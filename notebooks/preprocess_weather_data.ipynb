{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Weather Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.weather_scrape  import get_weather_data\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, stddev, mean, col, to_date, concat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the weather data from the NOAA website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 2022 for weather\n",
      "https://www.ncei.noaa.gov/oa/global-historical-climatology-network/hourly/access/by-year/2022/psv/GHCNh_USW00094728_2022.psv\n",
      "../data/landing/noaa_data/2022.psv\n",
      "Completed 2022 for weather\n",
      "Begin 2023 for weather\n",
      "https://www.ncei.noaa.gov/oa/global-historical-climatology-network/hourly/access/by-year/2023/psv/GHCNh_USW00094728_2023.psv\n",
      "../data/landing/noaa_data/2023.psv\n",
      "Completed 2023 for weather\n",
      "Begin 2022 for weather\n",
      "https://www.ncei.noaa.gov/oa/global-historical-climatology-network/hourly/access/by-year/2022/psv/GHCNh_USW00094728_2022.psv\n",
      "../data/raw/noaa_data/2022.psv\n",
      "Completed 2022 for weather\n",
      "Begin 2023 for weather\n",
      "https://www.ncei.noaa.gov/oa/global-historical-climatology-network/hourly/access/by-year/2023/psv/GHCNh_USW00094728_2023.psv\n",
      "../data/raw/noaa_data/2023.psv\n",
      "Completed 2023 for weather\n"
     ]
    }
   ],
   "source": [
    "get_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the weather dataframe: 15825 x 190\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Preprocess Weather Data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "years = [\"2022\", \"2023\"]\n",
    "\n",
    "weather_sdf_list = []\n",
    "for year in years:\n",
    "    # Read the PSV file into a DataFrame\n",
    "    psv_df = spark.read.format(\"csv\") \\\n",
    "        .option(\"delimiter\", \"|\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(f\"../data/raw/noaa_data/{year}.psv\")\n",
    "    weather_sdf_list.append(psv_df)\n",
    "\n",
    "# Join the data frames together to create a 2022 & 2023 dataframe\n",
    "weather_sdf = weather_sdf_list[0]\n",
    "weather_df = weather_sdf.union(weather_sdf_list[1])\n",
    "\n",
    "num_instances, num_features = weather_df.count(), len(weather_df.columns)\n",
    "print(f\"The shape of the weather dataframe: {num_instances} x {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 primary numerical features in the dataset with each attribute having several columns describing specific information about the main primary feature. These columns were often empty or beyond the scope of the research question and thus were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the weather dataframe: 15825 x 12\n"
     ]
    }
   ],
   "source": [
    "# Filter the relevant attributes\n",
    "attributes = [\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"Day\",\n",
    "    \"temperature\",\n",
    "    \"dew_point_temperature\",\n",
    "    \"station_level_pressure\",\n",
    "    \"sea_level_pressure\",\n",
    "    \"wind_speed\",\n",
    "    \"precipitation\",\n",
    "    \"relative_humidity\",\n",
    "    \"wet_bulb_temperature\"\n",
    "]\n",
    "\n",
    "weather_df = weather_df.select(attributes)\n",
    "\n",
    "# Feature engineered a date column\n",
    "weather_df = weather_df.withColumn(\n",
    "    \"date\",\n",
    "    to_date(\n",
    "        concat(\n",
    "            col(\"Year\"), \n",
    "            lit(\"-\"), \n",
    "            col(\"Month\"), \n",
    "            lit(\"-\"), \n",
    "            col(\"Day\")\n",
    "        ), \n",
    "        \"yyyy-MM-dd\"\n",
    "    )\n",
    ")\n",
    "\n",
    "weather_df = weather_df.orderBy(\"date\")\n",
    "\n",
    "num_instances, num_features = weather_df.count(), len(weather_df.columns)\n",
    "print(f\"The shape of the weather dataframe: {num_instances} x {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain general outline of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/25 00:29:34 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>Year</th><th>Month</th><th>Day</th><th>temperature</th><th>dew_point_temperature</th><th>station_level_pressure</th><th>sea_level_pressure</th><th>wind_speed</th><th>precipitation</th><th>relative_humidity</th><th>wet_bulb_temperature</th></tr>\n",
       "<tr><td>count</td><td>15825</td><td>15825</td><td>15825</td><td>15823</td><td>15822</td><td>15703</td><td>12370</td><td>15082</td><td>13881</td><td>15822</td><td>15703</td></tr>\n",
       "<tr><td>mean</td><td>2022.28897314376</td><td>5.465023696682464</td><td>15.479810426540284</td><td>12.1707767174366</td><td>4.836581974465858</td><td>1010.9803668088773</td><td>1016.8801050929648</td><td>2.369897891525936</td><td>0.2798645630718247</td><td>64.89072177980027</td><td>8.808590715149998</td></tr>\n",
       "<tr><td>stddev</td><td>0.4532997358330133</td><td>3.4220232816639076</td><td>8.877999213496155</td><td>8.992139178474988</td><td>10.06296335827768</td><td>8.174583374180722</td><td>7.920357844551943</td><td>1.6676380759587226</td><td>1.3536896464437305</td><td>22.002522477733766</td><td>8.215600892214656</td></tr>\n",
       "<tr><td>min</td><td>2022</td><td>01</td><td>01</td><td>-0.6</td><td>-0.6</td><td>1000.0</td><td>1000.0</td><td>0.0</td><td>0.0</td><td>10</td><td>-0.1</td></tr>\n",
       "<tr><td>max</td><td>2023</td><td>12</td><td>31</td><td>9.4</td><td>9.4</td><td>999.7</td><td>999.9</td><td>9.8</td><td>9.9</td><td>97</td><td>9.9</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+------------------+------------------+-----------------+---------------------+----------------------+------------------+------------------+------------------+------------------+--------------------+\n",
       "|summary|              Year|             Month|               Day|      temperature|dew_point_temperature|station_level_pressure|sea_level_pressure|        wind_speed|     precipitation| relative_humidity|wet_bulb_temperature|\n",
       "+-------+------------------+------------------+------------------+-----------------+---------------------+----------------------+------------------+------------------+------------------+------------------+--------------------+\n",
       "|  count|             15825|             15825|             15825|            15823|                15822|                 15703|             12370|             15082|             13881|             15822|               15703|\n",
       "|   mean|  2022.28897314376| 5.465023696682464|15.479810426540284| 12.1707767174366|    4.836581974465858|    1010.9803668088773|1016.8801050929648| 2.369897891525936|0.2798645630718247| 64.89072177980027|   8.808590715149998|\n",
       "| stddev|0.4532997358330133|3.4220232816639076| 8.877999213496155|8.992139178474988|    10.06296335827768|     8.174583374180722| 7.920357844551943|1.6676380759587226|1.3536896464437305|22.002522477733766|   8.215600892214656|\n",
       "|    min|              2022|                01|                01|             -0.6|                 -0.6|                1000.0|            1000.0|               0.0|               0.0|                10|                -0.1|\n",
       "|    max|              2023|                12|                31|              9.4|                  9.4|                 999.7|             999.9|               9.8|               9.9|                97|                 9.9|\n",
       "+-------+------------------+------------------+------------------+-----------------+---------------------+----------------------+------------------+------------------+------------------+------------------+--------------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the dates outside of 2022-10-01 to 2023-03-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the weather dataframe: 5603 x 12\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates\n",
    "start_date = \"2022-10-01\"\n",
    "end_date = \"2023-03-31\"\n",
    "\n",
    "# Filter df to only include the specified date range\n",
    "weather_df = weather_df.filter(\n",
    "    (col(\"date\") >= start_date) & (col(\"date\") <= end_date)\n",
    ")\n",
    "\n",
    "num_instances, num_features = weather_df.count(), len(weather_df.columns)\n",
    "print(f\"The shape of the weather dataframe: {num_instances} x {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather was generally distributed so we removed any instances beyond sqrt(2*log(N)) standard deviations away from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 140:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the weather dataframe: 3950 x 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for column in attributes:\n",
    "    stats = weather_df.agg(\n",
    "        mean(column).alias(\"mean\"),\n",
    "        stddev(column).alias(\"stddev\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    column_mean = stats[\"mean\"]\n",
    "    column_stddev = stats[\"stddev\"]\n",
    "\n",
    "    bound_sd = np.sqrt(2*np.log(weather_df.count()))\n",
    "\n",
    "    weather_df = weather_df.filter(\n",
    "        (col(column) >= column_mean - bound_sd * column_stddev) &\n",
    "        (col(column) <= column_mean + bound_sd * column_stddev)\n",
    "    )\n",
    "\n",
    "\n",
    "num_instances, num_features = weather_df.count(), len(weather_df.columns)\n",
    "print(f\"The shape of the weather dataframe: {num_instances} x {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the weather data into daily averages and construct the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the weather dataframe: 3950 x 12\n"
     ]
    }
   ],
   "source": [
    "daily_weather_df = weather_df.groupBy(\"date\").agg(\n",
    "    mean(\"temperature\").alias(\"mean_temperature\"),\n",
    "    mean(\"dew_point_temperature\").alias(\"mean_dew_point_temperature\"),\n",
    "    mean(\"station_level_pressure\").alias(\"mean_station_level_pressure\"),\n",
    "    mean(\"sea_level_pressure\").alias(\"mean_sea_level_pressure\"),\n",
    "    mean(\"wind_speed\").alias(\"mean_wind_speed\"),\n",
    "    mean(\"precipitation\").alias(\"mean_precipitation\"),\n",
    "    mean(\"relative_humidity\").alias(\"mean_relative_humidity\"),\n",
    "    mean(\"wet_bulb_temperature\").alias(\"mean_wet_bulb_temperature\")\n",
    ")\n",
    "\n",
    "daily_weather_df = daily_weather_df.orderBy(\"date\")\n",
    "\n",
    "num_instances, num_features = weather_df.count(), len(weather_df.columns)\n",
    "print(f\"The shape of the weather dataframe: {num_instances} x {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Export into data/curated\n",
    "daily_weather_df.write.mode('overwrite').parquet('../data/curated/weather_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
