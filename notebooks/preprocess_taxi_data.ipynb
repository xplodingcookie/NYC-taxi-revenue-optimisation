{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.yellow_green_taxi_scrape import get_taxi_data\n",
    "from scripts.utility import taxi_type_correction\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, stddev, mean, col, unix_timestamp, abs, round, to_date, count, when, dayofweek, sum\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the taxi data from the TLC website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin 10/2022 for yellow_taxi\n",
      "Completed 10/2022 for yellow_taxi\n",
      "Begin 11/2022 for yellow_taxi\n",
      "Completed 11/2022 for yellow_taxi\n",
      "Begin 12/2022 for yellow_taxi\n",
      "Completed 12/2022 for yellow_taxi\n",
      "Begin 01/2023 for yellow_taxi\n",
      "Completed 01/2023 for yellow_taxi\n",
      "Begin 02/2023 for yellow_taxi\n",
      "Completed 02/2023 for yellow_taxi\n",
      "Begin 03/2023 for yellow_taxi\n",
      "Completed 03/2023 for yellow_taxi\n",
      "Begin 10/2022 for green_taxi\n",
      "Completed 10/2022 for green_taxi\n",
      "Begin 11/2022 for green_taxi\n",
      "Completed 11/2022 for green_taxi\n",
      "Begin 12/2022 for green_taxi\n",
      "Completed 12/2022 for green_taxi\n",
      "Begin 01/2023 for green_taxi\n",
      "Completed 01/2023 for green_taxi\n",
      "Begin 02/2023 for green_taxi\n",
      "Completed 02/2023 for green_taxi\n",
      "Begin 03/2023 for green_taxi\n",
      "Completed 03/2023 for green_taxi\n"
     ]
    }
   ],
   "source": [
    "get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/08/24 23:56:59 WARN Utils: Your hostname, DESKTOP-N0VCA8U resolves to a loopback address: 127.0.1.1; using 172.23.106.248 instead (on interface eth0)\n",
      "24/08/24 23:56:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/24 23:57:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/24 23:57:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/08/24 23:57:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/08/24 23:57:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of green taxi dataframe: 409138 x 20\n",
      "The shape of yellow taxi dataframe: 19712164 x 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Preprocess Taxi Data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# sdf = spark data frame\n",
    "time_period = {\n",
    "        \"2022\": [10,11,12],\n",
    "        \"2023\": [1,2,3]\n",
    "    }\n",
    "\n",
    "# Read in the green taxi parquet files individually and correctly type cast them\n",
    "green_sdf_list = []\n",
    "for year, months in time_period.items():\n",
    "    for month in months:\n",
    "        month_str = str(month).zfill(2)\n",
    "        file_path = f\"../data/landing/tlc_data/green_taxi/{year}-{month_str}.parquet\"\n",
    "        df = spark.read.parquet(file_path)\n",
    "        # Type cast to correct type \n",
    "        df_casted = taxi_type_correction(df)\n",
    "        # Put into data/raw as it is now correctly type casted\n",
    "        df_casted.write.mode('overwrite').parquet(\n",
    "            f'../data/raw/tlc_data/green_taxi/{year}-{month_str}.parquet')\n",
    "        green_sdf_list.append(df_casted)\n",
    "\n",
    "# Read in the yellow taxi parquet files individually and correctly type cast them and correct\n",
    "# column name inconsistencies\n",
    "yellow_sdf_list = []\n",
    "for year, months in time_period.items():\n",
    "    for month in months:\n",
    "        month_str = str(month).zfill(2)\n",
    "        file_path = f\"../data/landing/tlc_data/yellow_taxi/{year}-{month_str}.parquet\"\n",
    "        df = spark.read.parquet(file_path)\n",
    "        df_casted = taxi_type_correction(df)\n",
    "        # Put into data/raw as it is now correctly type casted\n",
    "        df_casted.write.mode('overwrite').parquet(\n",
    "            f'../data/raw/tlc_data/green_taxi/{year}-{month_str}.parquet')\n",
    "        df_casted.withColumnRenamed(\"Airport_fee\", \"airport_fee\")\n",
    "        yellow_sdf_list.append(df_casted)\n",
    "\n",
    "# Concatenate the yellow and green taxi dataframes respectively\n",
    "yellow_sdf = yellow_sdf_list[0]\n",
    "green_sdf = green_sdf_list[0]\n",
    "for df in yellow_sdf_list[1:]:\n",
    "    yellow_sdf = yellow_sdf.union(df)\n",
    "for df in green_sdf_list[1:]:\n",
    "    green_sdf = green_sdf.union(df)\n",
    "\n",
    "num_green_instances, num_green_features = green_sdf.count(), len(green_sdf.columns)\n",
    "num_yellow_instance, num_yellow_features = yellow_sdf.count(), len(yellow_sdf.columns)\n",
    "print(f\"The shape of green taxi dataframe: {num_green_instances} x {num_green_features}\")\n",
    "print(f\"The shape of yellow taxi dataframe: {num_yellow_instance} x {num_yellow_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns to keep them consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = {\"VendorID\": \"vendor_id\",\n",
    "               \"RatecodeID\": \"ratecode_id\",\n",
    "               \"PULocationID\": \"pu_location_id\",\n",
    "               \"DOLocationID\": \"do_location_id\"}\n",
    "\n",
    "for key, value in column_name.items():\n",
    "    green_sdf = green_sdf.withColumnRenamed(key, value)\n",
    "    yellow_sdf = yellow_sdf.withColumnRenamed(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dictionary descriptions, lpep and tpep are equivalent so generalise to be pep. Ehail fee is not defined in the data dictionary descriptions and only exists in one of the taxi datasets so we remove. Trip_type is also a difference and is irrelvant to the research question so we can also remove this. Store_and_fwd_flag is not relevant to the research question so we can drop this column from both datasets. As airport fee exists for yellow taxis but doesnt for green taxis make a new column for green taxis called airport_fee but set it to 0 for all instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of green taxi dataframe: 409138 x 18\n",
      "The shape of yellow taxi dataframe: 19712164 x 18\n"
     ]
    }
   ],
   "source": [
    "# Drop ehail fee and add a column called airport fee with values initialised to 0\n",
    "green_sdf = green_sdf.drop(\"ehail_fee\", \"trip_type\", \"store_and_fwd_flag\")\n",
    "yellow_sdf = yellow_sdf.drop(\"store_and_fwd_flag\")\n",
    "green_sdf = green_sdf.withColumn(\"airport_fee\", lit(0))\n",
    "\n",
    "# Rename the datetime columns to match\n",
    "green_sdf = (green_sdf.withColumnRenamed(\"lpep_pickup_datetime\", \"pep_pickup_datetime\")\n",
    "                      .withColumnRenamed(\"lpep_dropoff_datetime\", \"pep_dropoff_datetime\"))\n",
    "\n",
    "yellow_sdf = (yellow_sdf.withColumnRenamed(\"tpep_pickup_datetime\", \"pep_pickup_datetime\")\n",
    "                        .withColumnRenamed(\"tpep_dropoff_datetime\", \"pep_dropoff_datetime\"))\n",
    "\n",
    "num_green_instances, num_green_features = green_sdf.count(), len(green_sdf.columns)\n",
    "num_yellow_instance, num_yellow_features = yellow_sdf.count(), len(yellow_sdf.columns)\n",
    "print(f\"The shape of green taxi dataframe: {num_green_instances} x {num_green_features}\")\n",
    "print(f\"The shape of yellow taxi dataframe: {num_yellow_instance} x {num_yellow_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the yellow and green taxi dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of taxi dataframe: 20121302 x 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "taxi_df = yellow_sdf.union(green_sdf)\n",
    "\n",
    "initial_num_data_instances, initial_num_data_features = taxi_df.count(), len(taxi_df.columns)\n",
    "print(f\"The shape of taxi dataframe: {initial_num_data_instances} x {initial_num_data_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the 5-number summary for each of the numerical attributes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 23:59:08 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " summary               | count               \n",
      " vendor_id             | 20121302            \n",
      " passenger_count       | 19469756            \n",
      " trip_distance         | 20121302            \n",
      " ratecode_id           | 19503681            \n",
      " pu_location_id        | 20087377            \n",
      " do_location_id        | 20121302            \n",
      " payment_type          | 20121302            \n",
      " fare_amount           | 20121302            \n",
      " extra                 | 20121302            \n",
      " mta_tax               | 20121302            \n",
      " tip_amount            | 20121302            \n",
      " tolls_amount          | 20121302            \n",
      " improvement_surcharge | 20121302            \n",
      " total_amount          | 20087377            \n",
      " congestion_surcharge  | 19469756            \n",
      " airport_fee           | 19503681            \n",
      "-RECORD 1------------------------------------\n",
      " summary               | mean                \n",
      " vendor_id             | 1.7371428548709225  \n",
      " passenger_count       | 1.374228521405199   \n",
      " trip_distance         | 6.774370724120715   \n",
      " ratecode_id           | 4.362079445413407   \n",
      " pu_location_id        | 162.78690572691497  \n",
      " do_location_id        | 161.18659971258322  \n",
      " payment_type          | 1.496419239669478   \n",
      " fare_amount           | 7.922191630048048   \n",
      " extra                 | 1.2588523878822577  \n",
      " mta_tax               | 0.5203576026044667  \n",
      " tip_amount            | 11.93980138511875   \n",
      " tolls_amount          | 0.5614294964631719  \n",
      " improvement_surcharge | 1.0750502159419772  \n",
      " total_amount          | 24.563566751161027  \n",
      " congestion_surcharge  | 2.2483979896820485  \n",
      " airport_fee           | 0.1016432487795509  \n",
      "-RECORD 2------------------------------------\n",
      " summary               | stddev              \n",
      " vendor_id             | 0.45508174189297795 \n",
      " passenger_count       | 0.9225296795932798  \n",
      " trip_distance         | 437.5723017113995   \n",
      " ratecode_id           | 23.43187193681167   \n",
      " pu_location_id        | 67.72933551632772   \n",
      " do_location_id        | 326.15216516378575  \n",
      " payment_type          | 3.1264387288851205  \n",
      " fare_amount           | 31345.75013516499   \n",
      " extra                 | 1.5815872647686178  \n",
      " mta_tax               | 0.49787817800205714 \n",
      " tip_amount            | 31345.730892383657  \n",
      " tolls_amount          | 2.074328793310341   \n",
      " improvement_surcharge | 3.808914560357337   \n",
      " total_amount          | 20.91203989146796   \n",
      " congestion_surcharge  | 0.8062009638315748  \n",
      " airport_fee           | 0.3462956412049996  \n",
      "-RECORD 3------------------------------------\n",
      " summary               | min                 \n",
      " vendor_id             | 1                   \n",
      " passenger_count       | 0.0                 \n",
      " trip_distance         | 0.0                 \n",
      " ratecode_id           | 1.0                 \n",
      " pu_location_id        | 0.0                 \n",
      " do_location_id        | 0.0                 \n",
      " payment_type          | -150.0              \n",
      " fare_amount           | -1.33391414E8       \n",
      " extra                 | -22.18              \n",
      " mta_tax               | -14.3               \n",
      " tip_amount            | -110.0              \n",
      " tolls_amount          | -73.3               \n",
      " improvement_surcharge | -150.3              \n",
      " total_amount          | -1635.8             \n",
      " congestion_surcharge  | -2.75               \n",
      " airport_fee           | -1.25               \n",
      "-RECORD 4------------------------------------\n",
      " summary               | max                 \n",
      " vendor_id             | 6                   \n",
      " passenger_count       | 99.0                \n",
      " trip_distance         | 389678.46           \n",
      " ratecode_id           | 265.0               \n",
      " pu_location_id        | 265.0               \n",
      " do_location_id        | 305189.98           \n",
      " payment_type          | 2020.2              \n",
      " fare_amount           | 5901.74             \n",
      " extra                 | 20.8                \n",
      " mta_tax               | 270.27              \n",
      " tip_amount            | 1.3339136353E8      \n",
      " tolls_amount          | 655.55              \n",
      " improvement_surcharge | 2021.0              \n",
      " total_amount          | 5902.54             \n",
      " congestion_surcharge  | 2.75                \n",
      " airport_fee           | 1.25                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = [\n",
    "    \"vendor_id\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"ratecode_id\",\n",
    "    \"pu_location_id\",\n",
    "    \"do_location_id\",\n",
    "    \"payment_type\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"improvement_surcharge\",\n",
    "    \"total_amount\",\n",
    "    \"congestion_surcharge\",\n",
    "    \"airport_fee\"\n",
    "]\n",
    "\n",
    "taxi_df.select(numeric_columns).describe().show(vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify and remove any instances where the data is incorrect or inconsistent. We can see some examples of that above where we have a negative total amount, payment_type as -150.0 etc, dates not being within the months that have been scraped, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of taxi dataframe after semantic filtering: 18112819 x 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define date range\n",
    "start_date = \"2022-10-01\"\n",
    "end_date = \"2023-03-31\"\n",
    "\n",
    "# Filter DataFrame\n",
    "taxi_df = taxi_df.filter(\n",
    "    (col(\"pep_pickup_datetime\") >= start_date) &\n",
    "    (col(\"pep_dropoff_datetime\") <= end_date)\n",
    ")\n",
    "\n",
    "# Fix semantic errors in the data\n",
    "taxi_df = taxi_df.where(\n",
    "                (col(\"passenger_count\") > 0) &\n",
    "                (col(\"trip_distance\") > 0) &\n",
    "                (col(\"ratecode_id\") >= 1) &\n",
    "                (col(\"ratecode_id\") <= 6) &\n",
    "                (col(\"payment_type\") >= 1) &\n",
    "                (col(\"payment_type\") <= 6) &\n",
    "                (col(\"fare_amount\") >= 2.50) &\n",
    "                (col(\"extra\") >= 0) &\n",
    "                (col(\"mta_tax\") >= 0) &\n",
    "                (col(\"tip_amount\") >= 0) &\n",
    "                (col(\"tolls_amount\") >= 0) &\n",
    "                (col(\"improvement_surcharge\") >= 0) &\n",
    "                (col(\"total_amount\") >= 0) &\n",
    "                (col(\"congestion_surcharge\") >= 0) &\n",
    "                (col(\"airport_fee\") >= 0) &\n",
    "                (col(\"airport_fee\") <= 1.25)\n",
    "                )\n",
    "\n",
    "# Define trip time in hours and filter time that is too little or negative\n",
    "taxi_df = taxi_df.withColumn(\n",
    "    \"trip_time_hours\",\n",
    "    (unix_timestamp(col(\"pep_dropoff_datetime\")) - unix_timestamp(col(\"pep_pickup_datetime\"))) / (60*60)\n",
    ")\n",
    "\n",
    "taxi_df = taxi_df.where((col(\"trip_time_hours\") > 0.02))\n",
    "\n",
    "# Find total_amount and calc_amount (calculated amount) difference to find errors in summation \n",
    "taxi_df = taxi_df.withColumn(\n",
    "                    \"calc_total_amount\",\n",
    "                    col(\"fare_amount\") + \n",
    "                    col(\"extra\") + \n",
    "                    col(\"mta_tax\") + \n",
    "                    col(\"tip_amount\") + \n",
    "                    col(\"improvement_surcharge\") + \n",
    "                    col(\"congestion_surcharge\") +\n",
    "                    col(\"tolls_amount\") +\n",
    "                    col(\"airport_fee\"))\n",
    "\n",
    "taxi_df = taxi_df.withColumn(\n",
    "    \"total_diff\",\n",
    "    round(abs(col(\"total_amount\") - col(\"calc_total_amount\")), 4)\n",
    ")\n",
    "\n",
    "# As small errors are bound to happen and airport_fee is often seen to not be added we can leave them as long\n",
    "# as the total difference is <= 3\n",
    "taxi_df.filter(\n",
    "    (col(\"total_diff\") <= 3)\n",
    ")\n",
    "\n",
    "num_data_instances, num_data_features = taxi_df.count(), len(taxi_df.columns)\n",
    "print(f\"The shape of taxi dataframe after semantic filtering: {num_data_instances} x {num_data_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inconsistency and semantically wrong data has been removed but outliers still exist so we can remove them by assuming a normal distribution and removing values beyond sqrt(2*log(N)) std away from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:=====================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of taxi dataframe after outlier removal: 17932561 x 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "continuous_columns = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\", \"mta_tax\",\n",
    "    \"tip_amount\", \n",
    "    \"tolls_amount\",\n",
    "    \"improvement_surcharge\",\n",
    "    \"total_amount\",\n",
    "    \"congestion_surcharge\",\n",
    "    \"airport_fee\",\n",
    "    \"trip_time_hours\"\n",
    "]\n",
    "\n",
    "for column in continuous_columns:\n",
    "    stats = taxi_df.agg(\n",
    "        mean(column).alias(\"mean\"),\n",
    "        stddev(column).alias(\"stddev\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    column_mean = stats[\"mean\"]\n",
    "    column_stddev = stats[\"stddev\"]\n",
    "\n",
    "    bound_sd = np.sqrt(2*np.log(taxi_df.count()))\n",
    "    \n",
    "    taxi_df = taxi_df.filter(\n",
    "        (col(column) >= column_mean - bound_sd * column_stddev) &\n",
    "        (col(column) <= column_mean + bound_sd * column_stddev)\n",
    "    )\n",
    "\n",
    "num_data_instances, num_data_features = taxi_df.count(), len(taxi_df.columns)\n",
    "print(f\"The shape of taxi dataframe after outlier removal: {num_data_instances} x {num_data_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our cleaned raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>vendor_id</th><th>passenger_count</th><th>trip_distance</th><th>ratecode_id</th><th>pu_location_id</th><th>do_location_id</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>trip_time_hours</th><th>calc_total_amount</th><th>total_diff</th></tr>\n",
       "<tr><td>count</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td><td>17932561</td></tr>\n",
       "<tr><td>mean</td><td>1.7463752109918935</td><td>1.4035802248212066</td><td>3.3976104578704387</td><td>1.0434077430435063</td><td>166.3248044715978</td><td>164.32863783371488</td><td>1.2034765697994838</td><td>16.479031296198638</td><td>1.309605258278505</td><td>0.4999999107768266</td><td>3.0924208527717387</td><td>0.47935937371323334</td><td>0.6746864042509274</td><td>24.37416179184664</td><td>2.353252820386335</td><td>0.10403108345762772</td><td>0.261590260526033</td><td>24.99238699959946</td><td>0.6267004556683219</td></tr>\n",
       "<tr><td>stddev</td><td>0.43508535480394644</td><td>0.9077292178959858</td><td>4.242937025709574</td><td>0.22750770069058313</td><td>64.08221625317614</td><td>69.30948343553915</td><td>0.4447302501716157</td><td>13.918165896855857</td><td>1.5703724063125268</td><td>1.335837853883535E-4</td><td>3.207902658574981</td><td>1.7057187022748401</td><td>0.34913400449911514</td><td>17.800789592257043</td><td>0.5876501097805554</td><td>0.3452772721230137</td><td>0.2020857037638375</td><td>17.811227187108017</td><td>1.098710458096016</td></tr>\n",
       "<tr><td>min</td><td>1</td><td>1.0</td><td>0.01</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.5</td><td>0.0</td><td>0.3</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.3</td><td>0.0</td><td>0.0</td><td>0.020277777777777777</td><td>3.3</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>2</td><td>6.0</td><td>145.53</td><td>6.0</td><td>265.0</td><td>265.0</td><td>4.0</td><td>107.0</td><td>10.3</td><td>0.5</td><td>22.8</td><td>10.66</td><td>1.0</td><td>127.38</td><td>2.75</td><td>1.25</td><td>4.660277777777778</td><td>129.95000000000002</td><td>5.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------------------+------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+\n",
       "|summary|          vendor_id|   passenger_count|     trip_distance|        ratecode_id|   pu_location_id|    do_location_id|      payment_type|       fare_amount|             extra|             mta_tax|        tip_amount|       tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        airport_fee|     trip_time_hours| calc_total_amount|        total_diff|\n",
       "+-------+-------------------+------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+\n",
       "|  count|           17932561|          17932561|          17932561|           17932561|         17932561|          17932561|          17932561|          17932561|          17932561|            17932561|          17932561|           17932561|             17932561|          17932561|            17932561|           17932561|            17932561|          17932561|          17932561|\n",
       "|   mean| 1.7463752109918935|1.4035802248212066|3.3976104578704387| 1.0434077430435063|166.3248044715978|164.32863783371488|1.2034765697994838|16.479031296198638| 1.309605258278505|  0.4999999107768266|3.0924208527717387|0.47935937371323334|   0.6746864042509274| 24.37416179184664|   2.353252820386335|0.10403108345762772|   0.261590260526033| 24.99238699959946|0.6267004556683219|\n",
       "| stddev|0.43508535480394644|0.9077292178959858| 4.242937025709574|0.22750770069058313|64.08221625317614| 69.30948343553915|0.4447302501716157|13.918165896855857|1.5703724063125268|1.335837853883535E-4| 3.207902658574981| 1.7057187022748401|  0.34913400449911514|17.800789592257043|  0.5876501097805554| 0.3452772721230137|  0.2020857037638375|17.811227187108017| 1.098710458096016|\n",
       "|    min|                  1|               1.0|              0.01|                1.0|              1.0|               1.0|               1.0|               2.5|               0.0|                 0.3|               0.0|                0.0|                  0.0|               3.3|                 0.0|                0.0|0.020277777777777777|               3.3|               0.0|\n",
       "|    max|                  2|               6.0|            145.53|                6.0|            265.0|             265.0|               4.0|             107.0|              10.3|                 0.5|              22.8|              10.66|                  1.0|            127.38|                2.75|               1.25|   4.660277777777778|129.95000000000002|               5.0|\n",
       "+-------+-------------------+------------------+------------------+-------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+---------------------+------------------+--------------------+-------------------+--------------------+------------------+------------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are looking at fare_amount to get a general idea of the amount per day per zone we can aggregate the mean on day and create an avg_amount_per_hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:=====================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of taxi averages dataframe: 17932561 x 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "taxi_df = taxi_df.withColumn(\"date\", to_date(col(\"pep_pickup_datetime\")))\n",
    "\n",
    "# Compute averages avg_total_amount and avg_amount_per_hour\n",
    "taxi_averages_df = (\n",
    "    taxi_df.groupBy(\"pu_location_id\", \"date\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_pickups\"),\n",
    "        mean((col(\"total_amount\") + col(\"calc_total_amount\")) / 2).alias(\"avg_total_amount\"),\n",
    "        mean(\"trip_time_hours\").alias(\"avg_trip_time\"),\n",
    "        mean(\"fare_amount\").alias(\"avg_fare_amount\"),\n",
    "        mean(\"passenger_count\").alias(\"avg_passenger_count\"),\n",
    "        mean(\"trip_distance\").alias(\"avg_trip_distance\"),\n",
    "        mean(\"extra\").alias(\"avg_extra\"),\n",
    "        mean(\"mta_tax\").alias(\"avg_mta_tax\"),\n",
    "        mean(\"tip_amount\").alias(\"avg_tip_amount\"),\n",
    "        mean(\"tolls_amount\").alias(\"avg_tolls_amount\"),\n",
    "        mean(\"improvement_surcharge\").alias(\"avg_improvement_surcharge\"),\n",
    "        mean(\"congestion_surcharge\").alias(\"avg_congestion_surcharge\"),\n",
    "        mean(\"airport_fee\").alias(\"avg_airport_fee\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"avg_amount_per_hour\",\n",
    "    col(\"avg_total_amount\") / col(\"avg_trip_time\")\n",
    ")\n",
    "\n",
    "# Compute total daily revenue per zone\n",
    "daily_zone_revenue_df = (\n",
    "    taxi_df.groupBy(\"pu_location_id\", \"date\")\n",
    "    .agg(\n",
    "        sum((col(\"total_amount\") + col(\"calc_total_amount\")) / 2).alias(\"daily_zone_revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Join the daily_zone_revenue_df back with the taxi_averages_df to include the daily_zone_revenue\n",
    "taxi_averages_df = taxi_averages_df.join(daily_zone_revenue_df, on=[\"pu_location_id\", \"date\"], how=\"left\")\n",
    "\n",
    "# Add days of the week (Mon = 1, Tues = 2, etc.)\n",
    "taxi_averages_df = taxi_averages_df.withColumn(\"day_of_week\",\n",
    "                   when(dayofweek(taxi_averages_df.date) == 1, 7)\n",
    "                   .otherwise(dayofweek(taxi_averages_df.date) - 1))\n",
    "\n",
    "taxi_averages_df = taxi_averages_df.orderBy(\"date\")\n",
    "\n",
    "num_data_avg_instances, num_data_avg_features = taxi_averages_df.count(), len(taxi_averages_df.columns)\n",
    "print(f\"The shape of taxi averages dataframe: {num_data_instances} x {num_data_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/25 00:12:10 WARN DAGScheduler: Broadcasting large task binary with size 1222.7 KiB\n"
     ]
    }
   ],
   "source": [
    "# Export into data/curated\n",
    "taxi_df.write.mode('overwrite').parquet('../data/curated/cleaned_taxi_data.parquet')\n",
    "taxi_averages_df.write.mode('overwrite').parquet('../data/curated/taxi_averages_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
